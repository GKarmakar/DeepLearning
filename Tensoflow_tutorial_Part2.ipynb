{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "datapoint_size = 1000\n",
    "batch_size = 1\n",
    "steps = 100\n",
    "actual_W = 2\n",
    "actual_b = 10\n",
    "learn_rate = 0.001\n",
    "log_file = \"/tmp/feature_1_batch_1\"\n",
    "\n",
    "# Model linear regression y = Wx + b\n",
    "x = tf.placeholder(tf.float32, [None, 1], name=\"x\")\n",
    "W = tf.Variable(tf.zeros([1,1]), name=\"W\")\n",
    "b = tf.Variable(tf.zeros([1]), name=\"b\")\n",
    "with tf.name_scope(\"Wx_b\") as scope:\n",
    "  product = tf.matmul(x,W)\n",
    "  y = product + b\n",
    "\n",
    "# Add summary ops to collect data\n",
    "W_hist = tf.histogram_summary(\"weights\", W)\n",
    "b_hist = tf.histogram_summary(\"biases\", b)\n",
    "y_hist = tf.histogram_summary(\"y\", y)\n",
    "\n",
    "y_ = tf.placeholder(tf.float32, [None, 1], name=\"y_\")\n",
    "\n",
    "# Cost function sum((y_-y)**2)\n",
    "with tf.name_scope(\"cost\") as scope:\n",
    "  cost = tf.reduce_mean(tf.square(y_-y))\n",
    "  cost_sum = tf.scalar_summary(\"cost\", cost)\n",
    "\n",
    "# Training using Gradient Descent to minimize cost\n",
    "with tf.name_scope(\"train\") as scope:\n",
    "  train_step = tf.train.GradientDescentOptimizer(learn_rate).minimize(cost)\n",
    "\n",
    "all_xs = []\n",
    "all_ys = []\n",
    "for i in range(datapoint_size):\n",
    "  # Create fake data for y = W.x + b where W = 2, b = actual_b\n",
    "  all_xs.append(i%10)\n",
    "  all_ys.append(actual_W*(i%10)+actual_b)\n",
    "\n",
    "all_xs = np.transpose([all_xs])\n",
    "all_ys = np.transpose([all_ys])\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "# Merge all the summaries and write them out to /tmp/mnist_logs\n",
    "merged = tf.merge_all_summaries()\n",
    "writer = tf.train.SummaryWriter(log_file, sess.graph_def)\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(steps):\n",
    "  if datapoint_size == batch_size:\n",
    "    batch_start_idx = 0\n",
    "  elif datapoint_size < batch_size:\n",
    "    raise ValueError(\"datapoint_size: %d, must be greater than batch_size: %d\" % (datapoint_size, batch_size))\n",
    "  else:\n",
    "    batch_start_idx = (i * batch_size) % (datapoint_size - batch_size)\n",
    "  batch_end_idx = batch_start_idx + batch_size\n",
    "  batch_xs = all_xs[batch_start_idx:batch_end_idx]\n",
    "  batch_ys = all_ys[batch_start_idx:batch_end_idx]\n",
    "  xs = np.array(batch_xs)\n",
    "  ys = np.array(batch_ys)\n",
    "  # Record summary data, and the accuracy every 10 steps\n",
    "  if i % 10 == 0:\n",
    "    all_feed = { x: all_xs, y_: all_ys }\n",
    "    result = sess.run(merged, feed_dict=all_feed)\n",
    "    writer.add_summary(result, i)\n",
    "  else:\n",
    "    feed = { x: xs, y_: ys }\n",
    "    sess.run(train_step, feed_dict=feed)\n",
    "    print(\"y: %s\" % sess.run(y, feed_dict=feed))\n",
    "    print(\"y_: %s\" % ys)\n",
    "    print(\"cost: %f\" % sess.run(cost, feed_dict=feed))\n",
    "  print(\"After %d iteration:\" % i)\n",
    "  print(\"W: %f\" % sess.run(W))\n",
    "  print(\"b: %f\" % sess.run(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Basic Operation\n",
    "Tensor Types\n",
    "Project Speed Dating\n",
    "Placeholders and Feeding inputs\n",
    "Lazy Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provides extensive suite of functions and classes to build models from scratch. \n",
    "\n",
    "Off the self models aren't focus of tensoflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Flow Grpahs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It separates computation from actutal execution. Define compute as graph, assemble graphs and set sessions to execute them.\n",
    "\n",
    "Tensor: A n-dimensional matrix. In tesnorflow the information flows between nodes as tensors and compute applies to \n",
    "    tensors for tensor transformation.\n",
    "    \n",
    "    0-Dimensional --> Scalar\n",
    "    \n",
    "    1-Dimensional --> Vector\n",
    "    \n",
    "    2-Dimensional --> Matrix\n",
    "    \n",
    "    > 2 Dimensional --> Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nodes: Variables, constants and operators\n",
    "Edges: Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "a = tf.add(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have just defined a computational graph a where 2 and 3 are nodes pass on to an add operation to create another node a.\n",
    "But a is still not executed to generate addition of 2 & 3 to 5 because graph hasn't been executed yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing the output a --> an \"add\" operation with output of tensor shape 0 (scalar) of int32 data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = tf.add(3.0, 5.0)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to compute actual output of the add operation defined by the Graph we need to create a session. The objective of having \n",
    "session is to utilize all the compute resources available (cpu or gpu) and parallelize operation. \n",
    "This is concept of lazy execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(a)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happened with sess.run command is that tensorflow saw node named \"a\" and execute whatever necessary to compute node a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess: # This will do a implicit close of session once it come out of with\n",
    "    print(sess.run(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#lets look at another example\n",
    "x = 2\n",
    "y = 3\n",
    "\n",
    "op1 = tf.add(x,y)\n",
    "op2 = tf.mul(x,y)\n",
    "op3 = tf.pow(op2, op1)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(op3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#lets look at another example\n",
    "x = 2\n",
    "y = 3\n",
    "\n",
    "op1 = tf.add(x,y)\n",
    "op2 = tf.mul(x,y)\n",
    "useless = tf.mul(x, op1)\n",
    "op3 = tf.pow(op2, op1)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    op3, not_useless = sess.run([op3, useless])\n",
    "print(op3)\n",
    "print(not_useless)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tesnsorflow allows breaking graphs into many sub-graphs to execute them into mutiple CPU or GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#lets look at same example another way\n",
    "x = 2\n",
    "y = 3\n",
    "\n",
    "op1 = tf.add(x,y)\n",
    "op2 = tf.mul(x,y)\n",
    "useless = tf.mul(x, op1)\n",
    "op3 = tf.pow(op2, op1)\n",
    "\n",
    "fetches = [op3, useless]\n",
    "with tf.Session() as sess:\n",
    "    op3, not_useless = sess.run(fetches, feed_dict=None, options = None, run_metadata=None)\n",
    "print(op3)\n",
    "print(not_useless)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#to put a specific part of the graph into specific cpu or gpu\n",
    "\n",
    "\n",
    "#Create a grpah\n",
    "with tf.device(\"/gpu:2\"):\n",
    "    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0], shape = [1, 5], name = 'a')\n",
    "    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0], shape = [5, 1], name = 'b')\n",
    "    #b = tf.transpose(b)\n",
    "    c = tf.matmul(a, b)\n",
    "    #create a session with log_device_placement true\n",
    "    sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "    \n",
    "    #Run this session\n",
    "    print(sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 55.]]\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0], shape = [1, 5], name = 'a')\n",
    "b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0], shape = [5, 1], name = 'b')\n",
    "    #b = tf.transpose(b)\n",
    "c = tf.matmul(a, b)\n",
    "    #create a session with log_device_placement true\n",
    "#sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "sess = tf.Session()    \n",
    "    #Run this session\n",
    "print(sess.run(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple graphs needs multiple sessions, each will try to use all the available resources by default.\n",
    "\n",
    "Can't pass data between graphs without using python or numpy which isn't distributed.\n",
    "\n",
    "Its better to have disconnected subgraphs within a graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "#create a graph - other than default graphs\n",
    "\n",
    "\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    x = tf.add(2, 3)\n",
    "    sess = tf.Session(graph=g)\n",
    "    with tf.Session() as sess:\n",
    "        print(sess.run(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    a = 3\n",
    "    b = 2\n",
    "    x = tf.add(a, b)\n",
    "sess = tf.Session(graph=g)\n",
    "sess.run(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#to get the handle of the default graph\n",
    "g = tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#do Not mix graphs\n",
    "g1 = tf.get_default_graph()\n",
    "g2 = tf.Graph()\n",
    "\n",
    "with g1.as_default():\n",
    "    a = tf.constant(3)\n",
    "with g2.as_default():\n",
    "    b = tf.constant(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why Graphs:\n",
    "    Only run part of the graph that you need to execute - saves computation\n",
    "    Break graphs into small, differential pieces to facilitate auto differentiation\n",
    "    Facilitate distributed computation into multiple CPUs or GPUs.\n",
    "    Many machine learning models are created as directed graph already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
